{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nfrom PIL import Image\nfrom sklearn.metrics import multilabel_confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:31.985021Z","iopub.execute_input":"2024-03-24T12:03:31.985549Z","iopub.status.idle":"2024-03-24T12:03:35.361558Z","shell.execute_reply.started":"2024-03-24T12:03:31.985507Z","shell.execute_reply":"2024-03-24T12:03:35.360162Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense ,Dropout\nfrom tensorflow.keras.applications import VGG16, VGG19, ResNet50, ResNet101","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:35.367043Z","iopub.execute_input":"2024-03-24T12:03:35.367717Z","iopub.status.idle":"2024-03-24T12:03:53.805440Z","shell.execute_reply.started":"2024-03-24T12:03:35.367677Z","shell.execute_reply":"2024-03-24T12:03:53.803866Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-03-24 12:03:37.942995: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-24 12:03:37.943137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-24 12:03:38.109367: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Reading Data","metadata":{}},{"cell_type":"code","source":"complete_data_info = pd.read_csv(\"/kaggle/input/data/Data_Entry_2017.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:53.807144Z","iopub.execute_input":"2024-03-24T12:03:53.807994Z","iopub.status.idle":"2024-03-24T12:03:54.255178Z","shell.execute_reply.started":"2024-03-24T12:03:53.807954Z","shell.execute_reply":"2024-03-24T12:03:54.253736Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing\n\nIn this the path and file names of each .png image is separated and stored in a two different list and a new dataframe is made with these path and filenames and then it is merged with the complete data file. It is done as there is no path column in the dataset provided and we would need image path later. And then we have dropped unnecessary columns from the the complete_data_info. ","metadata":{}},{"cell_type":"code","source":"data_base_path = \"/kaggle/input/data\"","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:54.257949Z","iopub.execute_input":"2024-03-24T12:03:54.258993Z","iopub.status.idle":"2024-03-24T12:03:54.266075Z","shell.execute_reply.started":"2024-03-24T12:03:54.258931Z","shell.execute_reply":"2024-03-24T12:03:54.263984Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"complete_data_imgs_paths = list()\nimgs_file_names = list()\n\nfor single_img_path in Path(data_base_path).glob(\"images_*/images/*.png\"):\n    \n    complete_data_imgs_paths.append(str(single_img_path))\n    imgs_file_names.append(str(single_img_path.parts[-1]))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:54.268315Z","iopub.execute_input":"2024-03-24T12:03:54.270670Z","iopub.status.idle":"2024-03-24T12:03:59.259571Z","shell.execute_reply.started":"2024-03-24T12:03:54.270610Z","shell.execute_reply":"2024-03-24T12:03:59.257246Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"complete_data_path_info = pd.DataFrame(data={\"Image Index\":imgs_file_names,\n                                            \"Image Path\":complete_data_imgs_paths})","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.262195Z","iopub.execute_input":"2024-03-24T12:03:59.262751Z","iopub.status.idle":"2024-03-24T12:03:59.315786Z","shell.execute_reply.started":"2024-03-24T12:03:59.262707Z","shell.execute_reply":"2024-03-24T12:03:59.314318Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"complete_data_all_info = complete_data_info.merge(complete_data_path_info,on=\"Image Index\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.317471Z","iopub.execute_input":"2024-03-24T12:03:59.318014Z","iopub.status.idle":"2024-03-24T12:03:59.551648Z","shell.execute_reply.started":"2024-03-24T12:03:59.317976Z","shell.execute_reply":"2024-03-24T12:03:59.550282Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"complete_data_all_info.drop(complete_data_all_info.columns[2:6],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.553445Z","iopub.execute_input":"2024-03-24T12:03:59.553898Z","iopub.status.idle":"2024-03-24T12:03:59.582087Z","shell.execute_reply.started":"2024-03-24T12:03:59.553859Z","shell.execute_reply":"2024-03-24T12:03:59.579844Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"complete_data_all_info.drop([\"Unnamed: 11\"],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.584094Z","iopub.execute_input":"2024-03-24T12:03:59.584790Z","iopub.status.idle":"2024-03-24T12:03:59.608952Z","shell.execute_reply.started":"2024-03-24T12:03:59.584744Z","shell.execute_reply":"2024-03-24T12:03:59.607857Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Reading the Testing data","metadata":{}},{"cell_type":"code","source":"testing_data_info = pd.read_csv(\"/kaggle/input/data/BBox_List_2017.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.613422Z","iopub.execute_input":"2024-03-24T12:03:59.613925Z","iopub.status.idle":"2024-03-24T12:03:59.629640Z","shell.execute_reply.started":"2024-03-24T12:03:59.613885Z","shell.execute_reply":"2024-03-24T12:03:59.628431Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Getting the training data from complete data - testing data","metadata":{}},{"cell_type":"code","source":"complete_data_all_info = complete_data_all_info.set_index(\"Image Index\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.631472Z","iopub.execute_input":"2024-03-24T12:03:59.632953Z","iopub.status.idle":"2024-03-24T12:03:59.680034Z","shell.execute_reply.started":"2024-03-24T12:03:59.632897Z","shell.execute_reply":"2024-03-24T12:03:59.678720Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"testing_data_path_info = complete_data_all_info.loc[testing_data_info[\"Image Index\"]]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.682700Z","iopub.execute_input":"2024-03-24T12:03:59.683846Z","iopub.status.idle":"2024-03-24T12:03:59.721719Z","shell.execute_reply.started":"2024-03-24T12:03:59.683784Z","shell.execute_reply":"2024-03-24T12:03:59.720510Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"training_data_all_info = complete_data_all_info.drop(index=testing_data_path_info.index)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.723388Z","iopub.execute_input":"2024-03-24T12:03:59.724074Z","iopub.status.idle":"2024-03-24T12:03:59.778582Z","shell.execute_reply.started":"2024-03-24T12:03:59.724036Z","shell.execute_reply":"2024-03-24T12:03:59.776849Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"testing_data_path_info.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.780369Z","iopub.execute_input":"2024-03-24T12:03:59.780929Z","iopub.status.idle":"2024-03-24T12:03:59.790104Z","shell.execute_reply.started":"2024-03-24T12:03:59.780878Z","shell.execute_reply":"2024-03-24T12:03:59.788379Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Adding path info to the testing data and deleting unnecessary coumns from the testing data","metadata":{}},{"cell_type":"code","source":"testing_data_all_info = testing_data_info.merge(testing_data_path_info,\n                                               on=\"Image Index\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.792425Z","iopub.execute_input":"2024-03-24T12:03:59.793255Z","iopub.status.idle":"2024-03-24T12:03:59.808359Z","shell.execute_reply.started":"2024-03-24T12:03:59.793196Z","shell.execute_reply":"2024-03-24T12:03:59.806671Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"testing_data_all_info.drop(labels=testing_data_all_info.columns[6:9],axis=1,\n                          inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.810177Z","iopub.execute_input":"2024-03-24T12:03:59.810703Z","iopub.status.idle":"2024-03-24T12:03:59.820905Z","shell.execute_reply.started":"2024-03-24T12:03:59.810662Z","shell.execute_reply":"2024-03-24T12:03:59.819560Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"training_data_all_info.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.822897Z","iopub.execute_input":"2024-03-24T12:03:59.823713Z","iopub.status.idle":"2024-03-24T12:03:59.873762Z","shell.execute_reply.started":"2024-03-24T12:03:59.823670Z","shell.execute_reply":"2024-03-24T12:03:59.872652Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                          Finding Labels View Position  OriginalImage[Width  \\\nImage Index                                                                   \n00000001_000.png            Cardiomegaly            PA                 2682   \n00000001_001.png  Cardiomegaly|Emphysema            PA                 2894   \n00000001_002.png   Cardiomegaly|Effusion            PA                 2500   \n00000002_000.png              No Finding            PA                 2500   \n00000003_000.png                  Hernia            PA                 2582   \n\n                  Height]  OriginalImagePixelSpacing[x     y]  \\\nImage Index                                                     \n00000001_000.png     2749                        0.143  0.143   \n00000001_001.png     2729                        0.143  0.143   \n00000001_002.png     2048                        0.168  0.168   \n00000002_000.png     2048                        0.171  0.171   \n00000003_000.png     2991                        0.143  0.143   \n\n                                                         Image Path  \nImage Index                                                          \n00000001_000.png  /kaggle/input/data/images_001/images/00000001_...  \n00000001_001.png  /kaggle/input/data/images_001/images/00000001_...  \n00000001_002.png  /kaggle/input/data/images_001/images/00000001_...  \n00000002_000.png  /kaggle/input/data/images_001/images/00000002_...  \n00000003_000.png  /kaggle/input/data/images_001/images/00000003_...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Finding Labels</th>\n      <th>View Position</th>\n      <th>OriginalImage[Width</th>\n      <th>Height]</th>\n      <th>OriginalImagePixelSpacing[x</th>\n      <th>y]</th>\n      <th>Image Path</th>\n    </tr>\n    <tr>\n      <th>Image Index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00000001_000.png</th>\n      <td>Cardiomegaly</td>\n      <td>PA</td>\n      <td>2682</td>\n      <td>2749</td>\n      <td>0.143</td>\n      <td>0.143</td>\n      <td>/kaggle/input/data/images_001/images/00000001_...</td>\n    </tr>\n    <tr>\n      <th>00000001_001.png</th>\n      <td>Cardiomegaly|Emphysema</td>\n      <td>PA</td>\n      <td>2894</td>\n      <td>2729</td>\n      <td>0.143</td>\n      <td>0.143</td>\n      <td>/kaggle/input/data/images_001/images/00000001_...</td>\n    </tr>\n    <tr>\n      <th>00000001_002.png</th>\n      <td>Cardiomegaly|Effusion</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.168</td>\n      <td>0.168</td>\n      <td>/kaggle/input/data/images_001/images/00000001_...</td>\n    </tr>\n    <tr>\n      <th>00000002_000.png</th>\n      <td>No Finding</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.171</td>\n      <td>0.171</td>\n      <td>/kaggle/input/data/images_001/images/00000002_...</td>\n    </tr>\n    <tr>\n      <th>00000003_000.png</th>\n      <td>Hernia</td>\n      <td>PA</td>\n      <td>2582</td>\n      <td>2991</td>\n      <td>0.143</td>\n      <td>0.143</td>\n      <td>/kaggle/input/data/images_001/images/00000003_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"testing_data_all_info.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.875627Z","iopub.execute_input":"2024-03-24T12:03:59.876474Z","iopub.status.idle":"2024-03-24T12:03:59.901052Z","shell.execute_reply.started":"2024-03-24T12:03:59.876421Z","shell.execute_reply":"2024-03-24T12:03:59.899771Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"        Image Index Finding Label     Bbox [x           y           w  \\\n0  00013118_008.png   Atelectasis  225.084746  547.019217   86.779661   \n1  00014716_007.png   Atelectasis  686.101695  131.543498  185.491525   \n2  00029817_009.png   Atelectasis  221.830508  317.053115  155.118644   \n3  00014687_001.png   Atelectasis  726.237288  494.951420  141.016949   \n4  00017877_001.png   Atelectasis  660.067797  569.780787  200.677966   \n\n           h]                          Finding Labels View Position  \\\n0   79.186441                             Atelectasis            PA   \n1  313.491525               Atelectasis|Effusion|Mass            AP   \n2  216.949153                             Atelectasis            AP   \n3   55.322034  Atelectasis|Cardiomegaly|Consolidation            AP   \n4   78.101695                             Atelectasis            AP   \n\n   OriginalImage[Width  Height]  OriginalImagePixelSpacing[x     y]  \\\n0                 2992     2991                        0.143  0.143   \n1                 3056     2544                        0.139  0.139   \n2                 3056     2544                        0.139  0.139   \n3                 2500     2048                        0.168  0.168   \n4                 2500     2048                        0.168  0.168   \n\n                                          Image Path  \n0  /kaggle/input/data/images_006/images/00013118_...  \n1  /kaggle/input/data/images_007/images/00014716_...  \n2  /kaggle/input/data/images_012/images/00029817_...  \n3  /kaggle/input/data/images_007/images/00014687_...  \n4  /kaggle/input/data/images_008/images/00017877_...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image Index</th>\n      <th>Finding Label</th>\n      <th>Bbox [x</th>\n      <th>y</th>\n      <th>w</th>\n      <th>h]</th>\n      <th>Finding Labels</th>\n      <th>View Position</th>\n      <th>OriginalImage[Width</th>\n      <th>Height]</th>\n      <th>OriginalImagePixelSpacing[x</th>\n      <th>y]</th>\n      <th>Image Path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00013118_008.png</td>\n      <td>Atelectasis</td>\n      <td>225.084746</td>\n      <td>547.019217</td>\n      <td>86.779661</td>\n      <td>79.186441</td>\n      <td>Atelectasis</td>\n      <td>PA</td>\n      <td>2992</td>\n      <td>2991</td>\n      <td>0.143</td>\n      <td>0.143</td>\n      <td>/kaggle/input/data/images_006/images/00013118_...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00014716_007.png</td>\n      <td>Atelectasis</td>\n      <td>686.101695</td>\n      <td>131.543498</td>\n      <td>185.491525</td>\n      <td>313.491525</td>\n      <td>Atelectasis|Effusion|Mass</td>\n      <td>AP</td>\n      <td>3056</td>\n      <td>2544</td>\n      <td>0.139</td>\n      <td>0.139</td>\n      <td>/kaggle/input/data/images_007/images/00014716_...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00029817_009.png</td>\n      <td>Atelectasis</td>\n      <td>221.830508</td>\n      <td>317.053115</td>\n      <td>155.118644</td>\n      <td>216.949153</td>\n      <td>Atelectasis</td>\n      <td>AP</td>\n      <td>3056</td>\n      <td>2544</td>\n      <td>0.139</td>\n      <td>0.139</td>\n      <td>/kaggle/input/data/images_012/images/00029817_...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00014687_001.png</td>\n      <td>Atelectasis</td>\n      <td>726.237288</td>\n      <td>494.951420</td>\n      <td>141.016949</td>\n      <td>55.322034</td>\n      <td>Atelectasis|Cardiomegaly|Consolidation</td>\n      <td>AP</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.168</td>\n      <td>0.168</td>\n      <td>/kaggle/input/data/images_007/images/00014687_...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00017877_001.png</td>\n      <td>Atelectasis</td>\n      <td>660.067797</td>\n      <td>569.780787</td>\n      <td>200.677966</td>\n      <td>78.101695</td>\n      <td>Atelectasis</td>\n      <td>AP</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.168</td>\n      <td>0.168</td>\n      <td>/kaggle/input/data/images_008/images/00017877_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Getting Unique Diseases\n\nUsing the map(), the list of Finding Labels is traversed and the diseases are split where there is a '|' and then it is merged on the list and we got a list of uniques diseaes as a result.  ","metadata":{}},{"cell_type":"code","source":"training_data_all_info[\"Finding Labels\"] = training_data_all_info[\"Finding Labels\"].map(lambda x: x.split(\"|\"))\ntesting_data_all_info[\"Finding Labels\"] = testing_data_all_info[\"Finding Labels\"].map(lambda x: x.split(\"|\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:03:59.902867Z","iopub.execute_input":"2024-03-24T12:03:59.903626Z","iopub.status.idle":"2024-03-24T12:04:00.396446Z","shell.execute_reply.started":"2024-03-24T12:03:59.903585Z","shell.execute_reply":"2024-03-24T12:04:00.394750Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"merged_list = list()\n\nfor single_list in training_data_all_info[\"Finding Labels\"]:\n    \n    merged_list = merged_list + single_list\n\nunique_diseases = set(merged_list)\nunique_diseases = list(unique_diseases)\nunique_diseases.remove(\"No Finding\")\ndisease2idx = dict(zip(unique_diseases,range(0,len(unique_diseases))))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:04:00.398742Z","iopub.execute_input":"2024-03-24T12:04:00.399252Z","iopub.status.idle":"2024-03-24T12:04:56.557676Z","shell.execute_reply.started":"2024-03-24T12:04:00.399195Z","shell.execute_reply":"2024-03-24T12:04:56.555562Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"disease2idx","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:04:56.559555Z","iopub.execute_input":"2024-03-24T12:04:56.560021Z","iopub.status.idle":"2024-03-24T12:04:56.571159Z","shell.execute_reply.started":"2024-03-24T12:04:56.559981Z","shell.execute_reply":"2024-03-24T12:04:56.569425Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'Pneumothorax': 0,\n 'Edema': 1,\n 'Fibrosis': 2,\n 'Infiltration': 3,\n 'Mass': 4,\n 'Consolidation': 5,\n 'Pneumonia': 6,\n 'Cardiomegaly': 7,\n 'Atelectasis': 8,\n 'Pleural_Thickening': 9,\n 'Hernia': 10,\n 'Effusion': 11,\n 'Emphysema': 12,\n 'Nodule': 13}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Multihot Encoding of the Diseases\n\nIn this initially the list has zeros and if the image has has diseases the that index will be changed to one. In this we will create a multihot encoded vector for both training and testing data. This is done by ThreadPoolExecutor to manage and create threads. It is done using map(), it maps the method and iterables together immediately and will raise an exception concurrent.futures.TimeoutError if it fails to do so within the timeout limit.","metadata":{}},{"cell_type":"code","source":"def map_diseases(disease_list):\n    \n    all_zeros = np.zeros(len(disease2idx),)\n    \n    for single_disease in disease_list:\n        \n        if single_disease != \"No Finding\":\n            all_zeros[disease2idx[single_disease]] = 1\n        \n    return all_zeros","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:04:56.573001Z","iopub.execute_input":"2024-03-24T12:04:56.573480Z","iopub.status.idle":"2024-03-24T12:04:56.591326Z","shell.execute_reply.started":"2024-03-24T12:04:56.573439Z","shell.execute_reply":"2024-03-24T12:04:56.589683Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"with ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n    \n    multi_hot_encoded_Y_train = np.array(list(pool.map(map_diseases,training_data_all_info[\"Finding Labels\"])))\n    multi_hot_encoded_Y_test = np.array(list(pool.map(map_diseases,testing_data_all_info[\"Finding Labels\"])))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:04:56.593056Z","iopub.execute_input":"2024-03-24T12:04:56.593574Z","iopub.status.idle":"2024-03-24T12:05:04.449785Z","shell.execute_reply.started":"2024-03-24T12:04:56.593534Z","shell.execute_reply":"2024-03-24T12:05:04.448116Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"training_data_all_info.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:04.451836Z","iopub.execute_input":"2024-03-24T12:05:04.452439Z","iopub.status.idle":"2024-03-24T12:05:04.462268Z","shell.execute_reply.started":"2024-03-24T12:05:04.452391Z","shell.execute_reply":"2024-03-24T12:05:04.460726Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Training and Testing data are stored in .csv files after all the preprocessing.","metadata":{}},{"cell_type":"code","source":"training_data_all_info.to_csv(\"training_data.csv\",index=False)\ntesting_data_all_info.to_csv(\"testing_data.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:04.463808Z","iopub.execute_input":"2024-03-24T12:05:04.464320Z","iopub.status.idle":"2024-03-24T12:05:05.658512Z","shell.execute_reply.started":"2024-03-24T12:05:04.464272Z","shell.execute_reply":"2024-03-24T12:05:05.657040Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"In custom_training_data_generator(), the minibatch from the training is selected at random and then it ","metadata":{}},{"cell_type":"code","source":"def custom_training_data_generator(training_data_all_info,multi_hot_encoded_Y_train,mb_size):\n    idx = list(training_data_all_info.index)\n    np.random.shuffle(idx)\n    training_data_all_info=training_data_all_info.iloc[idx]\n    multi_hot_encoded_Y_train=multi_hot_encoded_Y_train[idx]\n    \n    for time_step in range (training_data_all_info.shape[0]//mb_size):\n        X_train_mb=list()\n        \n        for single_img_path in training_data_all_info.iloc[time_step*mb_size:(time_step+1)*mb_size][\"Image Path\"]:\n#             resized_single_img = cv2.resize(Image.open(single_img_path).convert(\"RGB\"),(1024,1024))\n    \n#             X_train_mb.append(resized_single_img)\n             # Open the image using PIL\n            pil_img = Image.open(single_img_path).convert(\"RGB\")\n\n            # Convert PIL image to numpy array\n            np_img = np.array(pil_img)\n\n            # Resize the numpy array\n            resized_single_img = cv2.resize(np_img, (1024, 1024))\n\n            X_train_mb.append(resized_single_img)\n            \n        X_train_mb=np.array(X_train_mb)\n        \n        Y_train_mb=multi_hot_encoded_Y_train[time_step*mb_size:(time_step+1)*mb_size]\n        \n        yield X_train_mb,Y_train_mb","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:05.660387Z","iopub.execute_input":"2024-03-24T12:05:05.660859Z","iopub.status.idle":"2024-03-24T12:05:05.672508Z","shell.execute_reply.started":"2024-03-24T12:05:05.660822Z","shell.execute_reply":"2024-03-24T12:05:05.671022Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def custom_testing_data_generator(testing_data_all_info, multi_hot_encoded_Y_test, mb_size):\n    \n    for time_step in range(testing_data_all_info.shape[0]//mb_size):\n        \n        X_test_mb = list()\n        \n        for single_img_path in testing_data_all_info.iloc[time_step*mb_size:(time_step+1)*mb_size][\"Image Path\"]:\n            \n            resized_single_img =  cv2.resize(np.array(Image.open(single_img_path).convert(\"RGB\")),(1024,1024))\n            X_test_mb.append(resized_single_img)\n            \n        X_test_mb = np.array(X_test_mb)\n        Y_test_mb = multi_hot_encoded_Y_test[time_step*mb_size:(time_step+1)*mb_size]\n        \n        bbox_mb = np.array(testing_data_all_info.iloc[time_step*mb_size:(time_step+1)*mb_size,2:6])\n        centroid_mb = bbox_mb[:,0:2] + 0.5*np.concatenate((bbox_mb[:,3:4],bbox_mb[:,2:3]),axis=1)\n        \n        img_size_mb = np.array(testing_data_all_info.iloc[time_step*mb_size:(time_step+1)*mb_size,8:10])\n        ordered_img_size_mb = np.concatenate((img_size_mb[:,1:2],img_size_mb[:,0:1]),axis=1)\n        rescaled_centroid_mb = centroid_mb * (32/ordered_img_size_mb)\n        \n        yield X_test_mb, Y_test_mb, rescaled_centroid_mb","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:05.675151Z","iopub.execute_input":"2024-03-24T12:05:05.675721Z","iopub.status.idle":"2024-03-24T12:05:05.692914Z","shell.execute_reply.started":"2024-03-24T12:05:05.675667Z","shell.execute_reply":"2024-03-24T12:05:05.691406Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class GlobalLSEPooling2D(tf.keras.layers.Layer):\n    \n    def __init__(self,r_hyper_param):\n        super(GlobalLSEPooling2D, self).__init__()\n        self.r = r_hyper_param\n        \n    def call(self,concatenated_input):\n        x_star_per_channel = GlobalMaxPooling2D(keepdims=True)(concatenated_input)\n        shifted_pix_values = tf.math.exp(self.r*(concatenated_input - x_star_per_channel))\n        avged_output = GlobalAveragePooling2D(keepdims=True)(shifted_pix_values)\n        logged_output = (1/self.r)*tf.math.log(avged_output)\n        layer_output = x_star_per_channel + logged_output\n        \n        return layer_output","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:05.700911Z","iopub.execute_input":"2024-03-24T12:05:05.702051Z","iopub.status.idle":"2024-03-24T12:05:05.711663Z","shell.execute_reply.started":"2024-03-24T12:05:05.701982Z","shell.execute_reply":"2024-03-24T12:05:05.710020Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def chest_x_ray_cnn():\n    \n    input_to_cnn = Input(shape=(1024,1024,3))\n    \n    pretrained_vgg16_conv_base = VGG16(include_top=False,\n                                   input_shape=(1024,1024,3))\n    pretrained_vgg19_conv_base = VGG19(include_top=False,\n                                  input_shape=(1024,1024,3))\n    pretrained_resnet50_conv_base = ResNet50(include_top=False,\n                                        input_shape=(1024,1024,3))\n    pretrained_resnet101_conv_base = ResNet101(include_top=False,\n                                          input_shape=(1024,1024,3))\n\n    pretrained_vgg16_conv_base.trainable = False\n    pretrained_vgg19_conv_base.trainable = False\n    pretrained_resnet50_conv_base.trainable = False\n    pretrained_resnet101_conv_base.trainable = False\n    \n    vgg16_out = pretrained_vgg16_conv_base(input_to_cnn)\n    vgg19_out = pretrained_vgg19_conv_base(input_to_cnn)\n    resnet50_out = pretrained_resnet50_conv_base(input_to_cnn)\n    resnet101_out = pretrained_resnet101_conv_base(input_to_cnn)\n    \n    concatenated_output = Concatenate()([vgg16_out,vgg19_out,\n                                      resnet50_out,resnet101_out])\n    \n    pooled_output = GlobalLSEPooling2D(r_hyper_param=0.9)(concatenated_output)\n    flattened_output = Flatten()(pooled_output)\n    dropout_output = Dropout(0.5)(flattened_output)\n    \n    cnn_out = Dense(units=multi_hot_encoded_Y_train.shape[1],\n                    activation=\"sigmoid\")(dropout_output)\n    \n    return Model(inputs=input_to_cnn,outputs=cnn_out)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:05.713723Z","iopub.execute_input":"2024-03-24T12:05:05.714173Z","iopub.status.idle":"2024-03-24T12:05:05.727752Z","shell.execute_reply.started":"2024-03-24T12:05:05.714138Z","shell.execute_reply":"2024-03-24T12:05:05.726172Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:05.730044Z","iopub.execute_input":"2024-03-24T12:05:05.730737Z","iopub.status.idle":"2024-03-24T12:05:05.744660Z","shell.execute_reply.started":"2024-03-24T12:05:05.730679Z","shell.execute_reply":"2024-03-24T12:05:05.743209Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# def chest_x_ray_cnn():\n#     input_to_cnn = Input(shape=(1024, 1024, 3))\n\n#     pretrained_vgg16_conv_base = VGG16(include_top=False, input_shape=(1024, 1024, 3))\n#     pretrained_vgg19_conv_base = VGG19(include_top=False, input_shape=(1024, 1024, 3))\n#     pretrained_resnet50_conv_base = ResNet50(include_top=False, input_shape=(1024, 1024, 3))\n#     pretrained_resnet101_conv_base = ResNet101(include_top=False, input_shape=(1024, 1024, 3))\n\n#     pretrained_vgg16_conv_base.trainable = False\n#     pretrained_vgg19_conv_base.trainable = False\n#     pretrained_resnet50_conv_base.trainable = False\n#     pretrained_resnet101_conv_base.trainable = False\n\n#     vgg16_out = pretrained_vgg16_conv_base(input_to_cnn)\n#     vgg19_out = pretrained_vgg19_conv_base(input_to_cnn)\n#     resnet50_out = pretrained_resnet50_conv_base(input_to_cnn)\n#     resnet101_out = pretrained_resnet101_conv_base(input_to_cnn)\n\n#     concatenated_output = Concatenate()([vgg16_out, vgg19_out, resnet50_out, resnet101_out])\n\n#     pooled_output = GlobalAveragePooling2D()(concatenated_output)\n#     dense_output = Dense(units=512, activation='relu')(pooled_output)\n#     dropout_output = Dropout(0.5)(dense_output)  # Adding Dropout for regularization\n#     cnn_out = Dense(units=multi_hot_encoded_Y_train.shape[1], activation='sigmoid')(dropout_output)\n\n#     model = Model(inputs=input_to_cnn, outputs=cnn_out)\n\n#     # Compile the model\n#     optimizer = Adam(lr=0.001)  # Starting with a lower learning rate\n#     model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n#     return model\n\n# # Define a learning rate reduction callback\n# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n\n# # Usage:\n# model = chest_x_ray_cnn()\n# # model.fit(custom_training_data_generator, epochs=epochs, validation_data=validation_generator, callbacks=[reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:05.746943Z","iopub.execute_input":"2024-03-24T12:05:05.747480Z","iopub.status.idle":"2024-03-24T12:05:05.756516Z","shell.execute_reply.started":"2024-03-24T12:05:05.747436Z","shell.execute_reply":"2024-03-24T12:05:05.754870Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"our_custom_cnn = chest_x_ray_cnn()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:05.758388Z","iopub.execute_input":"2024-03-24T12:05:05.758992Z","iopub.status.idle":"2024-03-24T12:05:35.914030Z","shell.execute_reply.started":"2024-03-24T12:05:05.758949Z","shell.execute_reply":"2024-03-24T12:05:35.912907Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 3s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80134624/80134624 [==============================] - 3s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 4s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n171446536/171446536 [==============================] - 6s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"our_custom_cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:35.915760Z","iopub.execute_input":"2024-03-24T12:05:35.916999Z","iopub.status.idle":"2024-03-24T12:05:36.045384Z","shell.execute_reply.started":"2024-03-24T12:05:35.916934Z","shell.execute_reply":"2024-03-24T12:05:36.044029Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 1024, 1024, 3)]      0         []                            \n                                                                                                  \n vgg16 (Functional)          (None, 32, 32, 512)          1471468   ['input_1[0][0]']             \n                                                          8                                       \n                                                                                                  \n vgg19 (Functional)          (None, 32, 32, 512)          2002438   ['input_1[0][0]']             \n                                                          4                                       \n                                                                                                  \n resnet50 (Functional)       (None, 32, 32, 2048)         2358771   ['input_1[0][0]']             \n                                                          2                                       \n                                                                                                  \n resnet101 (Functional)      (None, 32, 32, 2048)         4265817   ['input_1[0][0]']             \n                                                          6                                       \n                                                                                                  \n concatenate (Concatenate)   (None, 32, 32, 5120)         0         ['vgg16[0][0]',               \n                                                                     'vgg19[0][0]',               \n                                                                     'resnet50[0][0]',            \n                                                                     'resnet101[0][0]']           \n                                                                                                  \n global_lse_pooling2d (Glob  (None, 1, 1, 5120)           0         ['concatenate[0][0]']         \n alLSEPooling2D)                                                                                  \n                                                                                                  \n flatten (Flatten)           (None, 5120)                 0         ['global_lse_pooling2d[0][0]']\n                                                                                                  \n dropout (Dropout)           (None, 5120)                 0         ['flatten[0][0]']             \n                                                                                                  \n dense (Dense)               (None, 14)                   71694     ['dropout[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 101056654 (385.50 MB)\nTrainable params: 71694 (280.05 KB)\nNon-trainable params: 100984960 (385.23 MB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def weighted_bcel(Y_train_mb,Y_pred_mb):\n    \n    cardinality_p = np.count_nonzero(Y_train_mb)\n    cardinality_n = (Y_train_mb.shape[0]*Y_train_mb.shape[1]) - cardinality_p\n    \n    epsilon = 1e-7\n    beta_p = (cardinality_p + cardinality_n + epsilon)/(cardinality_p + epsilon)\n    beta_n = (cardinality_p + cardinality_n + epsilon)/(cardinality_n + epsilon)\n    \n    Y_pred_mb = tf.clip_by_value(Y_pred_mb, epsilon, 1.0 - epsilon)\n    return -tf.reduce_mean(tf.reduce_mean(beta_p*Y_train_mb*tf.math.log(Y_pred_mb) \\\n                          + beta_n*(1-Y_train_mb)*tf.math.log(1-Y_pred_mb),axis=0))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:36.047188Z","iopub.execute_input":"2024-03-24T12:05:36.047644Z","iopub.status.idle":"2024-03-24T12:05:36.056962Z","shell.execute_reply.started":"2024-03-24T12:05:36.047607Z","shell.execute_reply":"2024-03-24T12:05:36.055322Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def compute_performance_metrics(Y_pred,Y_true,thresh):\n    \n    Y_pred = Y_pred > thresh\n    confusion_matrix = multilabel_confusion_matrix(y_true=Y_true,y_pred=Y_pred)\n    summed_confusion_matrix = np.sum(confusion_matrix,axis=0)\n    \n    tp = summed_confusion_matrix[0,0]\n    tn = summed_confusion_matrix[1,1]\n    fp = summed_confusion_matrix[0,1]\n    fn = summed_confusion_matrix[1,0]\n    \n    accuracy = (tp+tn)/(tp+tn+fp+fn)\n    precision = tp/(tp+fp)\n    recall = tp/(tp+fn)\n    \n    return accuracy,precision,recall    ","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:36.058817Z","iopub.execute_input":"2024-03-24T12:05:36.059289Z","iopub.status.idle":"2024-03-24T12:05:36.073594Z","shell.execute_reply.started":"2024-03-24T12:05:36.059220Z","shell.execute_reply":"2024-03-24T12:05:36.071901Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def predicted_center_pixel_cords(heatmaps):\n    \n    argmax = list()\n    for single_heatmap in heatmaps:\n        \n        heatmap_channels = cv2.split(single_heatmap)\n        argmax_per_heatmap = list()\n    \n        for single_heatmap_channel in heatmap_channels:    \n            single_channel_max_loc = list(np.unravel_index(np.argmax(single_heatmap_channel),single_heatmap_channel.shape))\n            argmax_per_heatmap.append(single_channel_max_loc)\n        \n        argmax.append(np.array(argmax_per_heatmap)/np.array([[7,7]])*224)\n        \n    return np.array(argmax)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:36.075673Z","iopub.execute_input":"2024-03-24T12:05:36.076160Z","iopub.status.idle":"2024-03-24T12:05:36.086109Z","shell.execute_reply.started":"2024-03-24T12:05:36.076118Z","shell.execute_reply":"2024-03-24T12:05:36.084788Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"conv_base = Model(inputs=[our_custom_cnn.input],outputs=[our_custom_cnn.layers[5].output])","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:36.087649Z","iopub.execute_input":"2024-03-24T12:05:36.088058Z","iopub.status.idle":"2024-03-24T12:05:36.104017Z","shell.execute_reply.started":"2024-03-24T12:05:36.088027Z","shell.execute_reply":"2024-03-24T12:05:36.102519Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train_data = training_data_all_info[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:36.106256Z","iopub.execute_input":"2024-03-24T12:05:36.106792Z","iopub.status.idle":"2024-03-24T12:05:36.114554Z","shell.execute_reply.started":"2024-03-24T12:05:36.106741Z","shell.execute_reply":"2024-03-24T12:05:36.112557Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:36.116505Z","iopub.execute_input":"2024-03-24T12:05:36.117052Z","iopub.status.idle":"2024-03-24T12:05:36.143704Z","shell.execute_reply.started":"2024-03-24T12:05:36.117000Z","shell.execute_reply":"2024-03-24T12:05:36.142532Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"        Image Index             Finding Labels View Position  \\\n0  00000001_000.png             [Cardiomegaly]            PA   \n1  00000001_001.png  [Cardiomegaly, Emphysema]            PA   \n2  00000001_002.png   [Cardiomegaly, Effusion]            PA   \n3  00000002_000.png               [No Finding]            PA   \n4  00000003_000.png                   [Hernia]            PA   \n\n   OriginalImage[Width  Height]  OriginalImagePixelSpacing[x     y]  \\\n0                 2682     2749                        0.143  0.143   \n1                 2894     2729                        0.143  0.143   \n2                 2500     2048                        0.168  0.168   \n3                 2500     2048                        0.171  0.171   \n4                 2582     2991                        0.143  0.143   \n\n                                          Image Path  \n0  /kaggle/input/data/images_001/images/00000001_...  \n1  /kaggle/input/data/images_001/images/00000001_...  \n2  /kaggle/input/data/images_001/images/00000001_...  \n3  /kaggle/input/data/images_001/images/00000002_...  \n4  /kaggle/input/data/images_001/images/00000003_...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image Index</th>\n      <th>Finding Labels</th>\n      <th>View Position</th>\n      <th>OriginalImage[Width</th>\n      <th>Height]</th>\n      <th>OriginalImagePixelSpacing[x</th>\n      <th>y]</th>\n      <th>Image Path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000001_000.png</td>\n      <td>[Cardiomegaly]</td>\n      <td>PA</td>\n      <td>2682</td>\n      <td>2749</td>\n      <td>0.143</td>\n      <td>0.143</td>\n      <td>/kaggle/input/data/images_001/images/00000001_...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000001_001.png</td>\n      <td>[Cardiomegaly, Emphysema]</td>\n      <td>PA</td>\n      <td>2894</td>\n      <td>2729</td>\n      <td>0.143</td>\n      <td>0.143</td>\n      <td>/kaggle/input/data/images_001/images/00000001_...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000001_002.png</td>\n      <td>[Cardiomegaly, Effusion]</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.168</td>\n      <td>0.168</td>\n      <td>/kaggle/input/data/images_001/images/00000001_...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000002_000.png</td>\n      <td>[No Finding]</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.171</td>\n      <td>0.171</td>\n      <td>/kaggle/input/data/images_001/images/00000002_...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000003_000.png</td>\n      <td>[Hernia]</td>\n      <td>PA</td>\n      <td>2582</td>\n      <td>2991</td>\n      <td>0.143</td>\n      <td>0.143</td>\n      <td>/kaggle/input/data/images_001/images/00000003_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"mhe_Ytrain = multi_hot_encoded_Y_train[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:36.145759Z","iopub.execute_input":"2024-03-24T12:05:36.146281Z","iopub.status.idle":"2024-03-24T12:05:36.152791Z","shell.execute_reply.started":"2024-03-24T12:05:36.146210Z","shell.execute_reply":"2024-03-24T12:05:36.151081Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"mhe_Ytrain[0:2]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:36.155093Z","iopub.execute_input":"2024-03-24T12:05:36.155720Z","iopub.status.idle":"2024-03-24T12:05:36.168166Z","shell.execute_reply.started":"2024-03-24T12:05:36.155669Z","shell.execute_reply":"2024-03-24T12:05:36.166641Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.]])"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import LearningRateScheduler","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:36.170449Z","iopub.execute_input":"2024-03-24T12:05:36.170973Z","iopub.status.idle":"2024-03-24T12:05:36.181278Z","shell.execute_reply.started":"2024-03-24T12:05:36.170929Z","shell.execute_reply":"2024-03-24T12:05:36.179168Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def lr_scheduler(epoch, lr):\n    if epoch < 2:\n        return lr  # Keep the initial learning rate for the first 10 epochs\n    else:\n        return lr * tf.math.exp(-0.1)  # Exponential decay with a decay rate of 0.1 every epoch after the 10th epoch\n\n\noptimizer = tf.keras.optimizers.RMSprop(lr=0.001)\nour_custom_cnn.compile(optimizer=optimizer, loss=weighted_bcel, metrics=['accuracy'])\nlr_scheduler_callback = LearningRateScheduler(lr_scheduler)\n\n\nnum_epochs = 4\ntime_steps = 0\nmb_size = 2\n\nfor epoch in range(num_epochs):\n    for X_train_mb,Y_train_mb in custom_training_data_generator(train_data,mhe_Ytrain,mb_size):\n        \n        with tf.GradientTape() as tape:\n            \n            Y_pred_mb = our_custom_cnn(X_train_mb)\n            w_bcel_value = weighted_bcel(Y_train_mb,Y_pred_mb)\n            \n        gradients = tape.gradient(w_bcel_value,our_custom_cnn.trainable_weights)\n        optimizer.apply_gradients(zip(gradients,our_custom_cnn.trainable_weights))\n        \n        train_acc,train_pre,train_rec = compute_performance_metrics(Y_pred_mb,Y_train_mb,0.5)\n        \n        time_steps += 1\n            \n        print(\"\\n\\nEpoch # {}, Time Step # {}\".format(epoch,time_steps))\n        print(\"WBCEL Value = {}, Training Accuracy = {}, Training Precision = {}, Training Recall = {}\".format(w_bcel_value,\n                                                                                                              train_acc,\n                                                                                                              train_pre,\n                                                                                                              train_rec))\n        conv_base_out = conv_base(X_train_mb).numpy()\n        cls_head_params = our_custom_cnn.layers[-1].weights[0].numpy()\n        \n        heatmaps = np.matmul(conv_base_out,cls_head_params)\n        pred_center_pix_loc = predicted_center_pixel_cords(heatmaps)\n        \n        print(\"Epoch # {}, Time Step # {}, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\".format(epoch,\n                                                                                                                     time_steps))\n        print(pred_center_pix_loc)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:05:36.183627Z","iopub.execute_input":"2024-03-24T12:05:36.184805Z","iopub.status.idle":"2024-03-24T13:09:07.103080Z","shell.execute_reply.started":"2024-03-24T12:05:36.184745Z","shell.execute_reply":"2024-03-24T13:09:07.098045Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"\n\nEpoch # 0, Time Step # 1\nWBCEL Value = 22.6063232421875, Training Accuracy = 0.4642857142857143, Training Precision = 0.48148148148148145, Training Recall = 0.9285714285714286\nEpoch # 0, Time Step # 1, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0. 768.]\n  [  0. 928.]\n  [  0. 832.]\n  [  0. 800.]\n  [ 32. 992.]\n  [ 64. 768.]\n  [ 64. 960.]\n  [ 64. 768.]\n  [  0. 416.]\n  [ 96.   0.]\n  [  0. 256.]\n  [  0. 992.]\n  [  0. 512.]\n  [608.  96.]]\n\n [[512. 992.]\n  [992. 928.]\n  [992. 224.]\n  [  0. 512.]\n  [736. 448.]\n  [ 96. 896.]\n  [992. 992.]\n  [704. 224.]\n  [672. 640.]\n  [448. 128.]\n  [416. 960.]\n  [160.  96.]\n  [992. 864.]\n  [608. 864.]]]\n\n\nEpoch # 0, Time Step # 2\nWBCEL Value = 19.22898292541504, Training Accuracy = 0.6785714285714286, Training Precision = 0.76, Training Recall = 0.8636363636363636\nEpoch # 0, Time Step # 2, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[352. 480.]\n  [192.   0.]\n  [992. 992.]\n  [352.   0.]\n  [  0. 960.]\n  [960. 160.]\n  [ 96. 960.]\n  [ 96. 960.]\n  [  0. 512.]\n  [  0. 512.]\n  [ 96. 896.]\n  [960. 160.]\n  [992. 256.]\n  [  0. 896.]]\n\n [[  0.   0.]\n  [256. 992.]\n  [992. 992.]\n  [  0. 960.]\n  [ 32. 960.]\n  [160. 960.]\n  [576. 384.]\n  [384. 832.]\n  [352. 960.]\n  [  0. 384.]\n  [128. 896.]\n  [ 64. 960.]\n  [992. 896.]\n  [ 32. 448.]]]\n\n\nEpoch # 0, Time Step # 3\nWBCEL Value = 17.11039924621582, Training Accuracy = 0.8571428571428571, Training Precision = 0.9230769230769231, Training Recall = 0.9230769230769231\nEpoch # 0, Time Step # 3, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[512. 960.]\n  [928. 960.]\n  [928. 960.]\n  [ 32. 992.]\n  [992.  96.]\n  [576. 512.]\n  [ 32. 448.]\n  [  0.   0.]\n  [ 64.   0.]\n  [544.  96.]\n  [256.  32.]\n  [320. 192.]\n  [ 32. 736.]\n  [928. 992.]]\n\n [[576. 448.]\n  [320. 992.]\n  [ 32. 992.]\n  [ 32. 864.]\n  [  0. 960.]\n  [576. 384.]\n  [768. 992.]\n  [  0. 928.]\n  [  0. 416.]\n  [  0. 480.]\n  [ 32. 960.]\n  [768. 864.]\n  [  0. 992.]\n  [  0. 960.]]]\n\n\nEpoch # 0, Time Step # 4\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.8928571428571429, Training Precision = 1.0, Training Recall = 0.8928571428571429\nEpoch # 0, Time Step # 4, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.  64.]\n  [992. 896.]\n  [992. 288.]\n  [ 32. 992.]\n  [992.   0.]\n  [ 64. 672.]\n  [992. 480.]\n  [  0. 896.]\n  [256.  32.]\n  [416. 128.]\n  [ 32. 864.]\n  [ 32. 928.]\n  [992. 224.]\n  [704. 800.]]\n\n [[960. 896.]\n  [992. 896.]\n  [992. 832.]\n  [  0. 512.]\n  [992.  32.]\n  [672. 416.]\n  [992. 864.]\n  [ 32. 960.]\n  [448. 512.]\n  [544. 480.]\n  [ 96. 896.]\n  [ 64. 576.]\n  [992. 160.]\n  [512. 192.]]]\n\n\nEpoch # 0, Time Step # 5\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.8928571428571429, Training Precision = 1.0, Training Recall = 0.8928571428571429\nEpoch # 0, Time Step # 5, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.  64.]\n  [352. 992.]\n  [992. 736.]\n  [  0. 896.]\n  [ 96. 992.]\n  [736. 576.]\n  [352. 992.]\n  [ 32. 832.]\n  [  0. 512.]\n  [288. 416.]\n  [  0. 896.]\n  [192. 864.]\n  [992. 192.]\n  [448. 832.]]\n\n [[992. 960.]\n  [ 32. 480.]\n  [448. 992.]\n  [896.  32.]\n  [ 96. 960.]\n  [704. 384.]\n  [448. 992.]\n  [ 96. 992.]\n  [416. 992.]\n  [  0. 640.]\n  [ 64. 864.]\n  [ 64. 864.]\n  [  0.   0.]\n  [672. 640.]]]\n\n\nEpoch # 1, Time Step # 6\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.8928571428571429, Training Precision = 1.0, Training Recall = 0.8928571428571429\nEpoch # 1, Time Step # 6, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.  64.]\n  [992. 896.]\n  [992. 288.]\n  [ 32. 992.]\n  [992.   0.]\n  [ 64. 672.]\n  [992. 480.]\n  [  0. 896.]\n  [256.  32.]\n  [416. 128.]\n  [ 32. 864.]\n  [ 32. 928.]\n  [992. 224.]\n  [704. 800.]]\n\n [[352. 480.]\n  [192.   0.]\n  [992. 992.]\n  [352.   0.]\n  [  0. 960.]\n  [960. 160.]\n  [640. 992.]\n  [  0. 960.]\n  [  0. 512.]\n  [  0. 512.]\n  [ 96. 896.]\n  [960. 160.]\n  [992. 256.]\n  [  0. 896.]]]\n\n\nEpoch # 1, Time Step # 7\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.8928571428571429, Training Precision = 1.0, Training Recall = 0.8928571428571429\nEpoch # 1, Time Step # 7, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[992. 960.]\n  [ 32. 480.]\n  [448. 992.]\n  [896.  32.]\n  [ 96. 960.]\n  [704. 384.]\n  [448. 992.]\n  [ 96. 992.]\n  [416. 992.]\n  [  0. 640.]\n  [ 64. 864.]\n  [ 64. 864.]\n  [  0.   0.]\n  [672. 640.]]\n\n [[672. 704.]\n  [992. 928.]\n  [992. 224.]\n  [  0. 512.]\n  [960. 128.]\n  [ 96. 896.]\n  [992. 480.]\n  [ 32. 736.]\n  [672. 640.]\n  [448. 128.]\n  [416. 960.]\n  [160.  96.]\n  [992. 864.]\n  [608. 864.]]]\n\n\nEpoch # 1, Time Step # 8\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.9642857142857143, Training Precision = 1.0, Training Recall = 0.9642857142857143\nEpoch # 1, Time Step # 8, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[576. 448.]\n  [320. 992.]\n  [ 32. 992.]\n  [ 32. 864.]\n  [  0. 960.]\n  [576. 384.]\n  [768. 992.]\n  [  0. 928.]\n  [  0. 416.]\n  [  0. 480.]\n  [ 32. 960.]\n  [768. 864.]\n  [  0. 992.]\n  [  0. 960.]]\n\n [[  0. 768.]\n  [  0. 928.]\n  [  0. 832.]\n  [  0. 800.]\n  [992.   0.]\n  [ 64. 768.]\n  [416. 992.]\n  [  0. 576.]\n  [  0. 416.]\n  [ 96.   0.]\n  [  0. 256.]\n  [  0. 992.]\n  [  0. 512.]\n  [608.  96.]]]\n\n\nEpoch # 1, Time Step # 9\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.8928571428571429, Training Precision = 1.0, Training Recall = 0.8928571428571429\nEpoch # 1, Time Step # 9, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[960. 896.]\n  [992. 896.]\n  [992. 832.]\n  [  0. 512.]\n  [992.  32.]\n  [672. 416.]\n  [992. 864.]\n  [ 32. 960.]\n  [448. 512.]\n  [544. 480.]\n  [ 96. 896.]\n  [ 64. 576.]\n  [992. 160.]\n  [512. 192.]]\n\n [[512. 960.]\n  [928. 960.]\n  [928. 960.]\n  [ 32. 992.]\n  [992.  96.]\n  [576. 512.]\n  [ 32. 448.]\n  [  0.   0.]\n  [ 64.   0.]\n  [544.  96.]\n  [256.  32.]\n  [320. 192.]\n  [ 32. 736.]\n  [928. 992.]]]\n\n\nEpoch # 1, Time Step # 10\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.9285714285714286, Training Precision = 1.0, Training Recall = 0.9285714285714286\nEpoch # 1, Time Step # 10, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.  64.]\n  [352. 992.]\n  [992. 736.]\n  [  0. 896.]\n  [ 96. 992.]\n  [736. 576.]\n  [352. 992.]\n  [ 32. 832.]\n  [  0. 512.]\n  [288. 416.]\n  [  0. 896.]\n  [192. 864.]\n  [992. 192.]\n  [448. 832.]]\n\n [[  0.   0.]\n  [256. 992.]\n  [992. 992.]\n  [  0. 960.]\n  [ 32. 960.]\n  [160. 960.]\n  [  0. 320.]\n  [  0. 512.]\n  [352. 960.]\n  [  0. 384.]\n  [128. 896.]\n  [ 64. 960.]\n  [992. 896.]\n  [ 32. 448.]]]\n\n\nEpoch # 2, Time Step # 11\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.9285714285714286, Training Precision = 1.0, Training Recall = 0.9285714285714286\nEpoch # 2, Time Step # 11, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[576. 448.]\n  [320. 992.]\n  [ 32. 992.]\n  [ 32. 864.]\n  [  0. 960.]\n  [576. 384.]\n  [768. 992.]\n  [  0. 928.]\n  [  0. 416.]\n  [  0. 480.]\n  [ 32. 960.]\n  [768. 864.]\n  [  0. 992.]\n  [  0. 960.]]\n\n [[672. 704.]\n  [992. 928.]\n  [992. 224.]\n  [  0. 512.]\n  [960. 128.]\n  [ 96. 896.]\n  [992. 480.]\n  [ 32. 736.]\n  [672. 640.]\n  [448. 128.]\n  [416. 960.]\n  [160.  96.]\n  [992. 864.]\n  [608. 864.]]]\n\n\nEpoch # 2, Time Step # 12\nWBCEL Value = 16.11809539794922, Training Accuracy = 0.8571428571428571, Training Precision = 1.0, Training Recall = 0.8571428571428571\nEpoch # 2, Time Step # 12, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[352. 480.]\n  [192.   0.]\n  [992. 992.]\n  [352.   0.]\n  [  0. 960.]\n  [960. 160.]\n  [640. 992.]\n  [  0. 960.]\n  [  0. 512.]\n  [  0. 512.]\n  [ 96. 896.]\n  [960. 160.]\n  [992. 256.]\n  [  0. 896.]]\n\n [[960. 896.]\n  [992. 896.]\n  [992. 832.]\n  [  0. 512.]\n  [992.  32.]\n  [672. 416.]\n  [992. 864.]\n  [ 32. 960.]\n  [448. 512.]\n  [544. 480.]\n  [ 96. 896.]\n  [ 64. 576.]\n  [992. 160.]\n  [512. 192.]]]\n\n\nEpoch # 2, Time Step # 13\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.9642857142857143, Training Precision = 1.0, Training Recall = 0.9642857142857143\nEpoch # 2, Time Step # 13, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[512. 960.]\n  [928. 960.]\n  [928. 960.]\n  [ 32. 992.]\n  [992.  96.]\n  [576. 512.]\n  [ 32. 448.]\n  [  0.   0.]\n  [ 64.   0.]\n  [544.  96.]\n  [256.  32.]\n  [320. 192.]\n  [ 32. 736.]\n  [928. 992.]]\n\n [[  0. 768.]\n  [  0. 928.]\n  [  0. 832.]\n  [  0. 800.]\n  [992.   0.]\n  [ 64. 768.]\n  [416. 992.]\n  [  0. 576.]\n  [  0. 416.]\n  [ 96.   0.]\n  [  0. 256.]\n  [  0. 992.]\n  [  0. 512.]\n  [608.  96.]]]\n\n\nEpoch # 2, Time Step # 14\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.8928571428571429, Training Precision = 1.0, Training Recall = 0.8928571428571429\nEpoch # 2, Time Step # 14, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.   0.]\n  [256. 992.]\n  [992. 992.]\n  [  0. 960.]\n  [ 32. 960.]\n  [160. 960.]\n  [  0. 320.]\n  [  0. 512.]\n  [352. 960.]\n  [  0. 384.]\n  [128. 896.]\n  [ 64. 960.]\n  [992. 896.]\n  [ 32. 448.]]\n\n [[992. 960.]\n  [ 32. 480.]\n  [448. 992.]\n  [896.  32.]\n  [ 96. 960.]\n  [704. 384.]\n  [448. 992.]\n  [ 96. 992.]\n  [416. 992.]\n  [  0. 640.]\n  [ 64. 864.]\n  [ 64. 864.]\n  [  0.   0.]\n  [672. 640.]]]\n\n\nEpoch # 2, Time Step # 15\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.9285714285714286, Training Precision = 1.0, Training Recall = 0.9285714285714286\nEpoch # 2, Time Step # 15, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.  64.]\n  [992. 896.]\n  [992. 288.]\n  [ 32. 992.]\n  [992.   0.]\n  [ 64. 672.]\n  [992. 480.]\n  [  0. 896.]\n  [256.  32.]\n  [416. 128.]\n  [ 32. 864.]\n  [ 32. 928.]\n  [992. 224.]\n  [704. 800.]]\n\n [[  0.  64.]\n  [352. 992.]\n  [992. 736.]\n  [  0. 896.]\n  [ 96. 992.]\n  [736. 576.]\n  [352. 992.]\n  [ 32. 832.]\n  [  0. 512.]\n  [288. 416.]\n  [  0. 896.]\n  [192. 864.]\n  [992. 192.]\n  [448. 832.]]]\n\n\nEpoch # 3, Time Step # 16\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.8928571428571429, Training Precision = 1.0, Training Recall = 0.8928571428571429\nEpoch # 3, Time Step # 16, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.  64.]\n  [992. 896.]\n  [992. 288.]\n  [ 32. 992.]\n  [992.   0.]\n  [ 64. 672.]\n  [992. 480.]\n  [  0. 896.]\n  [256.  32.]\n  [416. 128.]\n  [ 32. 864.]\n  [ 32. 928.]\n  [992. 224.]\n  [704. 800.]]\n\n [[960. 896.]\n  [992. 896.]\n  [992. 832.]\n  [  0. 512.]\n  [992.  32.]\n  [672. 416.]\n  [992. 864.]\n  [ 32. 960.]\n  [448. 512.]\n  [544. 480.]\n  [ 96. 896.]\n  [ 64. 576.]\n  [992. 160.]\n  [512. 192.]]]\n\n\nEpoch # 3, Time Step # 17\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.8928571428571429, Training Precision = 1.0, Training Recall = 0.8928571428571429\nEpoch # 3, Time Step # 17, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[992. 960.]\n  [ 32. 480.]\n  [448. 992.]\n  [896.  32.]\n  [ 96. 960.]\n  [704. 384.]\n  [448. 992.]\n  [ 96. 992.]\n  [416. 992.]\n  [  0. 640.]\n  [ 64. 864.]\n  [ 64. 864.]\n  [  0.   0.]\n  [672. 640.]]\n\n [[  0.  64.]\n  [352. 992.]\n  [992. 736.]\n  [  0. 896.]\n  [ 96. 992.]\n  [736. 576.]\n  [352. 992.]\n  [ 32. 832.]\n  [  0. 512.]\n  [288. 416.]\n  [  0. 896.]\n  [192. 864.]\n  [992. 192.]\n  [448. 832.]]]\n\n\nEpoch # 3, Time Step # 18\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.9285714285714286, Training Precision = 1.0, Training Recall = 0.9285714285714286\nEpoch # 3, Time Step # 18, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[576. 448.]\n  [320. 992.]\n  [ 32. 992.]\n  [ 32. 864.]\n  [  0. 960.]\n  [576. 384.]\n  [768. 992.]\n  [  0. 928.]\n  [  0. 416.]\n  [  0. 480.]\n  [ 32. 960.]\n  [768. 864.]\n  [  0. 992.]\n  [  0. 960.]]\n\n [[512. 960.]\n  [928. 960.]\n  [928. 960.]\n  [ 32. 992.]\n  [992.  96.]\n  [576. 512.]\n  [ 32. 448.]\n  [  0.   0.]\n  [ 64.   0.]\n  [544.  96.]\n  [256.  32.]\n  [320. 192.]\n  [ 32. 736.]\n  [928. 992.]]]\n\n\nEpoch # 3, Time Step # 19\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.9642857142857143, Training Precision = 1.0, Training Recall = 0.9642857142857143\nEpoch # 3, Time Step # 19, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.   0.]\n  [256. 992.]\n  [992. 992.]\n  [  0. 960.]\n  [ 32. 960.]\n  [160. 960.]\n  [  0. 320.]\n  [  0. 512.]\n  [352. 960.]\n  [  0. 384.]\n  [128. 896.]\n  [ 64. 960.]\n  [992. 896.]\n  [ 32. 448.]]\n\n [[  0. 768.]\n  [  0. 928.]\n  [  0. 832.]\n  [  0. 800.]\n  [992.   0.]\n  [ 64. 768.]\n  [416. 992.]\n  [  0. 576.]\n  [  0. 416.]\n  [ 96.   0.]\n  [  0. 256.]\n  [  0. 992.]\n  [  0. 512.]\n  [608.  96.]]]\n\n\nEpoch # 3, Time Step # 20\nWBCEL Value = 16.118093490600586, Training Accuracy = 0.8928571428571429, Training Precision = 1.0, Training Recall = 0.8928571428571429\nEpoch # 3, Time Step # 20, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[352. 480.]\n  [192.   0.]\n  [992. 992.]\n  [352.   0.]\n  [  0. 960.]\n  [960. 160.]\n  [640. 992.]\n  [  0. 960.]\n  [  0. 512.]\n  [  0. 512.]\n  [ 96. 896.]\n  [960. 160.]\n  [992. 256.]\n  [  0. 896.]]\n\n [[672. 704.]\n  [992. 928.]\n  [992. 224.]\n  [  0. 512.]\n  [960. 128.]\n  [ 96. 896.]\n  [992. 480.]\n  [ 32. 736.]\n  [672. 640.]\n  [448. 128.]\n  [416. 960.]\n  [160.  96.]\n  [992. 864.]\n  [608. 864.]]]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = testing_data_all_info[0:4]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T13:09:07.118394Z","iopub.execute_input":"2024-03-24T13:09:07.121777Z","iopub.status.idle":"2024-03-24T13:09:07.151977Z","shell.execute_reply.started":"2024-03-24T13:09:07.121638Z","shell.execute_reply":"2024-03-24T13:09:07.149851Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"mhe_Ytest = multi_hot_encoded_Y_test[0:4]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T13:09:07.162446Z","iopub.execute_input":"2024-03-24T13:09:07.164287Z","iopub.status.idle":"2024-03-24T13:09:07.180852Z","shell.execute_reply.started":"2024-03-24T13:09:07.164191Z","shell.execute_reply":"2024-03-24T13:09:07.178545Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# print(\"\\n\\n\\n\\n\")\n\n# thresh_probability = np.arange(start=0.3,stop=0.5,step=0.1)\n# fold_size = 2\n# K = testing_data_all_info.shape[0]//fold_size\n\n# for fold_idx in range(K):\n#     for p_thresh in thresh_probability:\n        \n#         cv_data = pd.concat([test_data[0:(fold_idx*fold_size)],\n#                              test_data[(fold_idx+1)*fold_size:]],axis=0)\n        \n#         testing_data = test_data[(fold_idx*fold_size):(fold_idx+1)*fold_size]\n        \n#         multi_hot_encoded_Y_cv = np.concatenate((mhe_Ytest[0:(fold_idx*fold_size)],\n#                                                 mhe_Ytest[(fold_idx+1)*fold_size:]),\n#                                                 axis=0)\n        \n#         multi_hot_encoded_Y_test = mhe_Ytest[(fold_idx*fold_size):(fold_idx+1)*fold_size]\n        \n#         X_cv, Y_cv, rescaled_centroid_cv = custom_testing_data_generator(cv_data,multi_hot_encoded_Y_cv,\n#                                                                          cv_data.shape[0])\n        \n#         X_test, Y_test, rescaled_centroid_test = custom_testing_data_generator(testing_data,\n#                                                                                multi_hot_encoded_Y_test,\n#                                                                                testing_data.shape[0])\n        \n#         Y_pred_cv = our_custom_cnn(X_cv)\n#         cv_acc,cv_pre,cv_rec = compute_performance_metrics(Y_pred_cv,Y_cv,p_thresh)\n        \n#         cv_conv_base_out = conv_base(X_cv).numpy()\n#         cv_heatmaps = np.matmul(cv_conv_base_out,cls_head_weights)\n        \n#         Y_pred_test = our_custom_cnn(X_test)\n#         test_acc,test_pre,test_rec = compute_performance_metrics(Y_pred_test,Y_test,p_thresh)\n        \n#         test_conv_base_out = conv_base(X_test).numpy()\n#         test_heatmaps = np.matmul(test_conv_base_out,cls_head_weights)\n        \n#         print(\"Threshold Probability: {}, CV Acc: {}, CV Prec: {}, CV Rec: {}\".format(p_thresh,cv_acc,\n#                                                                                             cv_pre,\n#                                                                                             cv_rec))\n        \n#         print(\"Threshold Probability: {}, Test Acc: {}, Test Prec: {}, Test Rec: {}\".format(p_thresh,\n#                                                                                            test_acc,\n#                                                                                            test_pre,\n#                                                                                            test_rec))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T13:09:07.190394Z","iopub.execute_input":"2024-03-24T13:09:07.192151Z","iopub.status.idle":"2024-03-24T13:09:07.204862Z","shell.execute_reply.started":"2024-03-24T13:09:07.192064Z","shell.execute_reply":"2024-03-24T13:09:07.203383Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"x_test, y_test, z_test = custom_testing_data_generator(test_data, mhe_Ytest, 2 ).__next__()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T13:09:07.206580Z","iopub.execute_input":"2024-03-24T13:09:07.206998Z","iopub.status.idle":"2024-03-24T13:09:07.289610Z","shell.execute_reply.started":"2024-03-24T13:09:07.206967Z","shell.execute_reply":"2024-03-24T13:09:07.288204Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"x_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-24T13:09:07.291490Z","iopub.execute_input":"2024-03-24T13:09:07.291899Z","iopub.status.idle":"2024-03-24T13:09:07.303531Z","shell.execute_reply.started":"2024-03-24T13:09:07.291867Z","shell.execute_reply":"2024-03-24T13:09:07.302063Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(2, 1024, 1024, 3)"},"metadata":{}}]},{"cell_type":"code","source":"p_thresh = 0.3\nY_pred_test = our_custom_cnn(x_test)\ntest_acc,test_pre,test_rec = compute_performance_metrics(Y_pred_test,y_test,p_thresh)\ntest_conv_base_out = conv_base(x_test).numpy()\ntest_heatmaps = np.matmul(test_conv_base_out,cls_head_params)\nprint(\"Threshold Probability: {}, Test Acc: {}, Test Prec: {}, Test Rec: {}\".format(p_thresh,\n                                                                                           test_acc,\n                                                                                           test_pre,\n                                                                                           test_rec))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T13:09:07.305821Z","iopub.execute_input":"2024-03-24T13:09:07.306373Z","iopub.status.idle":"2024-03-24T13:10:18.543940Z","shell.execute_reply.started":"2024-03-24T13:09:07.306332Z","shell.execute_reply":"2024-03-24T13:10:18.542039Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Threshold Probability: 0.3, Test Acc: 0.8571428571428571, Test Prec: 1.0, Test Rec: 0.8571428571428571\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}